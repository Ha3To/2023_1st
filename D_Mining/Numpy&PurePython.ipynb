{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1KyXZRITAoi"
   },
   "source": [
    "# Homework 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oTSJq2ETAol"
   },
   "source": [
    "***Double Click here to edit this cell***\n",
    "\n",
    "- Name: 임태호\n",
    "- Student ID: 201903021\n",
    "- Submission date: 2023.05.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXvcWHxaTAom"
   },
   "source": [
    "# You must run this homework code on Google Colab\n",
    "\n",
    "- DON'T run on Google Colab Pro\n",
    "- DON'T use GPU or TPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n01VIfGlTAom"
   },
   "source": [
    "### You must run the following two cells to make sure you are running on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2xZTbMUATAom",
    "outputId": "584dd5d2-4d67-454c-804b-ce440fa4bffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2200.164\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
      "bogomips\t: 4400.32\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2200.164\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
      "bogomips\t: 4400.32\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tbZcgifhTAon",
    "outputId": "0700ae34-d035-424e-88c4-9ba82b251ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemTotal:       13297192 kB\n",
      "MemFree:         9293292 kB\n",
      "MemAvailable:   12420288 kB\n",
      "Buffers:          325264 kB\n",
      "Cached:          2955864 kB\n",
      "SwapCached:            0 kB\n",
      "Active:           608416 kB\n",
      "Inactive:        3171628 kB\n",
      "Active(anon):       1636 kB\n",
      "Inactive(anon):   475420 kB\n",
      "Active(file):     606780 kB\n",
      "Inactive(file):  2696208 kB\n",
      "Unevictable:           0 kB\n",
      "Mlocked:               0 kB\n",
      "SwapTotal:             0 kB\n",
      "SwapFree:              0 kB\n",
      "Dirty:               260 kB\n",
      "Writeback:             0 kB\n",
      "AnonPages:        492288 kB\n",
      "Mapped:           256580 kB\n",
      "Shmem:              2468 kB\n",
      "KReclaimable:     130916 kB\n",
      "Slab:             161884 kB\n",
      "SReclaimable:     130916 kB\n",
      "SUnreclaim:        30968 kB\n",
      "KernelStack:        4048 kB\n",
      "PageTables:         5900 kB\n",
      "NFS_Unstable:          0 kB\n",
      "Bounce:                0 kB\n",
      "WritebackTmp:          0 kB\n",
      "CommitLimit:     6648596 kB\n",
      "Committed_AS:    2512044 kB\n",
      "VmallocTotal:   34359738367 kB\n",
      "VmallocUsed:        8884 kB\n",
      "VmallocChunk:          0 kB\n",
      "Percpu:             1320 kB\n",
      "HardwareCorrupted:     0 kB\n",
      "AnonHugePages:     10240 kB\n",
      "ShmemHugePages:        0 kB\n",
      "ShmemPmdMapped:        0 kB\n",
      "FileHugePages:         0 kB\n",
      "FilePmdMapped:         0 kB\n",
      "CmaTotal:              0 kB\n",
      "CmaFree:               0 kB\n",
      "HugePages_Total:       0\n",
      "HugePages_Free:        0\n",
      "HugePages_Rsvd:        0\n",
      "HugePages_Surp:        0\n",
      "Hugepagesize:       2048 kB\n",
      "Hugetlb:               0 kB\n",
      "DirectMap4k:       80696 kB\n",
      "DirectMap2M:     4110336 kB\n",
      "DirectMap1G:    11534336 kB\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjPoREOUTAon"
   },
   "source": [
    "## Remark: gradient_descent.py, linear_algebra.py must be in the folder having this notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "kMTvr10gTAoo"
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "from gradient_descent import *\n",
    "from linear_algebra import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQYpUm9fTAoo"
   },
   "source": [
    "## Problem 1 (5 pts)\n",
    "\n",
    "- The following function has a minimum at $(2, 3)$\n",
    "$$\n",
    "f(x_1, x_2) = (x_1 - 2)^2 + (x_2 - 3)^2\n",
    "$$\n",
    "\n",
    "- We want to compute the minimum of $f$ using the gradient descent algorithm\n",
    "- Define a function (```f```) and gradient of function (```f_gradient```)\n",
    "- **Do NOT use numpy functions to define f and f_gradient**\n",
    "- **USE functions in linear_algebra.py**\n",
    "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "odnmsENOTAoo"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "\n",
    "def f(x):\n",
    "    return (x[0] - 2)**2 + (x[1] - 3)**2\n",
    "\n",
    "def f_gradient(x):\n",
    "    return [2*(x[0] - 2), 2*(x[1] - 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UQZ0AJ6ATAop",
    "outputId": "c1dc89e5-678e-4c08-d550-d2645b2436c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 388 µs, sys: 0 ns, total: 388 µs\n",
      "Wall time: 398 µs\n",
      "solution is [1.997524119921429, 2.996286179882144]\n",
      "++++++++++ Problem 1 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "init_x = [0.,0.]\n",
    "%time solution = minimize_batch(f, f_gradient, init_x, tolerance=0.00001)\n",
    "\n",
    "### correctness check\n",
    "print('solution is {}'.format(solution))\n",
    "EPSILON = 0.01\n",
    "cond1 = math.fabs(solution[0] - 2.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 3.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 1 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 1 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfkiEhGUTAop"
   },
   "source": [
    "## Problem 2 (10 pts)\n",
    "\n",
    "- The centroid of a finite set of $\\displaystyle {k}$ points $\\displaystyle \\mathbf {x} _{1},\\mathbf {x} _{2},\\ldots ,\\mathbf {x} _{k}$ in $\\displaystyle \\mathbb {R} ^{n}$ is\n",
    "$$\n",
    "\\mathbf {C} ={\\frac {\\mathbf {x} _{1}+\\mathbf {x} _{2}+\\cdots +\\mathbf {x} _{k}}{k}}\n",
    "$$\n",
    "\n",
    "- We want to compute a centroid by **minimizing the mean of squared Euclidean distances between itself and each point in the set**\n",
    "$$\n",
    "x_{\\text{centroid}} = \\text{argmin}_{\\text{c}} {\\frac{\\sum_{i=1}^{n}d({\\text{c}}, x_i)^2}{n}}\n",
    "$$\n",
    "- Define a function (```sq_dist```) and gradient of function (```sq_dist_gradient```)\n",
    "- **Do NOT use numpy functions to define sq_dist and sq_dist_gradient**\n",
    "- **USE functions in linear_algebra.py**\n",
    "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "ZTxorB4eTAop"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "from typing import List\n",
    "\n",
    "def sq_dist(c: List[float], X: List[List[float]]) -> float:\n",
    "    return sum(dot(vector_subtract(c, x), vector_subtract(c, x)) \n",
    "               for x in X)/len(X)\n",
    "\n",
    "def sq_dist_gradient(c: List[float], X: List[List[float]]) -> List[float]:\n",
    "    return [2*sum((c[i]-x[i]) for x in X)/len(X) for i in range(len(c))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "VJaOUhT7TAoq",
    "outputId": "a37d4a6a-4714-435c-9d29-3b370a01119b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 2.02 ms, total: 154 ms\n",
      "Wall time: 159 ms\n",
      "solution is [99.99885075808739, 700.1414374609791]\n",
      "++++++++++ Problem 2 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + np.random.randn(100,2)\n",
    "\n",
    "f = partial(sq_dist, X=X)\n",
    "gradient_f = partial(sq_dist_gradient, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print('solution is {}'.format(solution))\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 2 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nM7vJHLVTAoq",
    "outputId": "353ed860-dd91-45d6-9c80-4b9700f79f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 36s, sys: 316 ms, total: 2min 36s\n",
      "Wall time: 2min 37s\n",
      "solution is [99.99988468682913, 700.0052527466843]\n",
      "++++++++++ Problem 2 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + np.random.randn(100000,2)     # 100 thousands\n",
    "\n",
    "f = partial(sq_dist, X=X)\n",
    "gradient_f = partial(sq_dist_gradient, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print('solution is {}'.format(solution))\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '+'*10 + ' Problem 2 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7yntmzLTAoq"
   },
   "source": [
    "**Time taken in my computer**:\n",
    "```\n",
    "Wall time: 2min 22s\n",
    "solution is [99.99988468682913, 700.0052527466843]\n",
    "++++++++++ Problem 2 check passed ++++++++++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7fgh7jgTAoq"
   },
   "source": [
    "## Problem 3 (10 pts)\n",
    "\n",
    "- Continued from Problem 2\n",
    "- We want to compute a centroid\n",
    "- Define a function (```sq_dist_numpy```) and gradient of function (```sq_dist_gradient_numpy```)\n",
    "- **Use numpy functions to define sq_dist and sq_dist_gradient**\n",
    "- **Do NOT use functions in linear_algebra.py**\n",
    "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "0Kc8N1NdTAoq"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "def sq_dist_numpy(c: np.ndarray, X: np.ndarray) -> float:\n",
    "    return np.mean(np.sum((X - c)**2, axis=1))\n",
    "\n",
    "def sq_dist_gradient_numpy(c: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    return np.mean(2*(c - X), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_jACFQzbTAoq",
    "outputId": "327214ae-ae4b-4fa1-e880-f1568ee95525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.93 s, sys: 5.94 ms, total: 1.94 s\n",
      "Wall time: 1.95 s\n",
      "[99.99988468682913, 700.0052527466843]\n",
      "++++++++++ Problem 3 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + np.random.randn(100000,2)\n",
    "\n",
    "f = partial(sq_dist_numpy, X=X)\n",
    "gradient_f = partial(sq_dist_gradient_numpy, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print(solution)\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 3 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 3 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5NvFA_wTAor"
   },
   "source": [
    "**Time taken in my computer**:\n",
    "```\n",
    "Wall time: 1.49 s\n",
    "[99.99988468682913, 700.0052527466843]\n",
    "++++++++++ Problem 3 check passed ++++++++++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDNVh-yoTAor"
   },
   "source": [
    "## Problem 4 (10 pts)\n",
    "\n",
    "- We want to compute a centroid using Manhattan distance\n",
    "- Define a function (```abs_diff_numpy```) and gradient of function (```abs_diff_gradient_numpy```)\n",
    "- Use numpy functions to define abs_diff_numpy and abs_diff_gradient_numpy\n",
    "- Do NOT use functions in linear_algebra.py\n",
    "### <span style=\"color:red\">**Each function must have ONE line of code; Otherwise, you get zero point (0점)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "55ZIayypTAor"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "def abs_diff_numpy(c: np.ndarray, X: np.ndarray) -> float:\n",
    "    return np.mean(np.sum(np.abs(X - c), axis=1))\n",
    "\n",
    "def abs_diff_gradient_numpy(c: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    return np.mean(np.sign(c - X), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "H6e_wPjvTAor",
    "outputId": "1962cbc3-05af-4496-b0db-041346b0336a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.24 ms, sys: 0 ns, total: 7.24 ms\n",
      "Wall time: 7.38 ms\n",
      "[99.26, 99.34666666666666]\n",
      "++++++++++ Problem 4 check passed ++++++++++\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "np.random.seed(0)\n",
    "# c = np.array([100,700])\n",
    "# X = c + np.random.randn(100,2)\n",
    "c1 = np.array([100,100])\n",
    "X1 = c1 + np.random.randn(100,2)\n",
    "c2 = np.array([100,0])\n",
    "X2 = c2 + np.random.randn(100,2)\n",
    "c3 = np.array([0,100])\n",
    "X3 = c3 + np.random.randn(100,2)\n",
    "X  = np.vstack((X1, X2, X3)) \n",
    "\n",
    "f = partial(abs_diff_numpy, X=X)\n",
    "gradient_f = partial(abs_diff_gradient_numpy, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "%time solution = minimize_batch(f, gradient_f, init_x)\n",
    "\n",
    "### correctness check\n",
    "print(solution)\n",
    "EPSILON = 1\n",
    "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "cond2 = math.fabs(solution[1] - 100.0) <= EPSILON\n",
    "assert  all([cond1, cond2]), '-'*10 + ' Problem 4 check failed ' + '-'*10\n",
    "print('+'*10 + ' Problem 4 check passed ' + '+'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWqqcoeDTAor"
   },
   "source": [
    "## Problem 5 (15 pts)\n",
    "\n",
    "- We want to rewrite ```minimize_batch```.\n",
    "- Do NOT use ```step``` function; provide numpy style code using broadcasting\n",
    "    - Do NOT use ```[step(theta, gradient, -step_size) for step_size in step_sizes]```\n",
    "- Modify ```minimize_batch``` to take ```step_sizes``` as an argument\n",
    "- Modify ```minimize_batch``` to take maximum number of epochs as an argument\n",
    "    - epoch is the number of ```while``` loop iterations in the following code.\n",
    "- Modify ```minimize_batch``` to return ```epoch``` together with ```theta```\n",
    "- Modify ```minimize_batch``` to return ```None``` as solution if it does not converge within max_steps\n",
    "- **Use numpy functions to define sq_dist_numpy_1 and sq_dist_gradient_numpy_1**\n",
    "- **Do NOT use functions in linear_algebra.py**\n",
    "- If all done, now you have an enhanced numpy version of minimize_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mws2wlmFTAor"
   },
   "source": [
    "The following is ```minimize_batch``` in our textbook\n",
    "```python\n",
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    \"\"\"use gradient descent to find theta that minimizes target function\"\"\"\n",
    "\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "    theta = theta_0                           # set theta to initial value\n",
    "    target_fn = safe(target_fn)               # safe version of target_fn\n",
    "    value = target_fn(theta)                  # value we're minimizing\n",
    "\n",
    "    while True:\n",
    "        gradient = gradient_fn(theta)\n",
    "        next_thetas = [step(theta, gradient, -step_size)\n",
    "                       for step_size in step_sizes]\n",
    "\n",
    "        # choose the one that minimizes the error function\n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "\n",
    "        # stop if we're \"converging\"\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta\n",
    "        else:\n",
    "            theta, value = next_theta, next_value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "P-hzV9ezTAor"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "\n",
    "def minimize_batch_enhanced(target_fn, gradient_fn, theta_0, step_sizes, \n",
    "                            max_steps=10000, tolerance=0.000001):\n",
    "    \"\"\"use gradient descent to find theta that minimizes target function\"\"\"\n",
    "\n",
    "    theta = theta_0                           # set theta to initial value\n",
    "    target_fn = safe(target_fn)               # safe version of target_fn\n",
    "    epoch = []                                # initialize epoch as empty list\n",
    "    value = target_fn(theta)                  # value we're minimizing\n",
    "    for i in range(max_steps):\n",
    "        gradient = gradient_fn(theta)\n",
    "        next_thetas = theta - step_sizes[:, np.newaxis] \n",
    "        * gradient[np.newaxis, :]\n",
    "\n",
    "        # choose the one that minimizes the error function\n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "\n",
    "        # stop if we're \"converging\"\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return next_theta, len(epoch)\n",
    "        else:\n",
    "            theta, value = next_theta, next_value\n",
    "            epoch.append(i)\n",
    "    return None, len(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xAMc0nWTAos"
   },
   "source": [
    "### <span style=\"color:red\">**Each function must have ONE line of code; Otherwise, you get zero point (0점)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "IercNRSgTAos"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE MUST BE HERE\n",
    "def sq_dist_numpy_1(c, X):\n",
    "    return np.sum(np.square(X - c), axis=1).mean()\n",
    "\n",
    "def sq_dist_gradient_numpy_1(c, X):\n",
    "    return 2 * np.mean(c - X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zbM7oDeWTAos",
    "outputId": "7e9cdb9a-cd29-45d6-eb8f-8a2d39864574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution [ 99.78194335 699.89611463] found at epoch 587\n",
      "Problem 5 check passed\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + 10*np.random.randn(1000,2)\n",
    "\n",
    "f = partial(sq_dist_numpy_1, X=X)\n",
    "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "step_sizes = np.array([0.01])\n",
    "\n",
    "solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
    "### correctness check\n",
    "if solution is None:\n",
    "    print('Does not converge within epoch {}'.format(epoch))\n",
    "else:\n",
    "    print('Solution {} found at epoch {}'.format(solution, epoch))\n",
    "    EPSILON = 1\n",
    "    cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "    cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "    assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
    "    print('Problem 5 check passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB9HWOs_TAos"
   },
   "source": [
    "Your solution should be like:\n",
    "```\n",
    "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
    "Problem 5 check passed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "AsUXr2l4TAos",
    "outputId": "2ff41888-7884-470c-f3b6-3cc2db6d0a1b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++ Test case [10] ++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-b653e548a857>:3: RuntimeWarning: overflow encountered in square\n",
      "  return np.sum(np.square(X - c), axis=1).mean()\n",
      "<ipython-input-83-74fce34460e8>:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if abs(value - next_value) < tolerance:\n",
      "<ipython-input-83-74fce34460e8>:12: RuntimeWarning: invalid value encountered in subtract\n",
      "  next_thetas = theta - step_sizes[:, np.newaxis] * gradient[np.newaxis, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does not converge within epoch 10000\n",
      "\n",
      "++++++++++ Test case [0.1] ++++++++++\n",
      "Solution [ 99.78248224 699.89989458] found at epoch 59\n",
      "Problem 5 check passed\n",
      "\n",
      "++++++++++ Test case [0.01] ++++++++++\n",
      "Solution [ 99.78194335 699.89611463] found at epoch 587\n",
      "Problem 5 check passed\n",
      "\n",
      "++++++++++ Test case [0.001] ++++++++++\n",
      "Solution [ 99.78040954 699.88535611] found at epoch 5349\n",
      "Problem 5 check passed\n",
      "\n",
      "++++++++++ Test case [0.0001] ++++++++++\n",
      "Does not converge within epoch 10000\n",
      "\n",
      "++++++++++ Test case [1.e-05] ++++++++++\n",
      "Does not converge within epoch 10000\n",
      "\n",
      "++++++++++ Test case [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03] ++++++++++\n",
      "Solution [ 99.78248224 699.89989458] found at epoch 59\n",
      "Problem 5 check passed\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# RUN THIS CELL\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "c = np.array([100,700])\n",
    "X = c + 10*np.random.randn(1000,2)\n",
    "\n",
    "f = partial(sq_dist_numpy_1, X=X)\n",
    "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
    "init_x = np.array([0.,0.])\n",
    "step_sizes_set = [np.array([10]),\n",
    "                  np.array([0.1]),\n",
    "                  np.array([0.01]),\n",
    "                  np.array([0.001]), \n",
    "                  np.array([0.0001]),\n",
    "                  np.array([0.00001]),\n",
    "                  np.array(np.logspace(-3,3,7))\n",
    "                 ]\n",
    "\n",
    "for step_sizes in step_sizes_set:\n",
    "    print()\n",
    "    print('+'*10 + ' Test case {} '.format(step_sizes) + '+'*10)\n",
    "    solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
    "    ### correctness check\n",
    "    if solution is None:\n",
    "        print('Does not converge within epoch {}'.format(epoch))\n",
    "    else:\n",
    "        print('Solution {} found at epoch {}'.format(solution, epoch))\n",
    "        EPSILON = 1\n",
    "        cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
    "        cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
    "        assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
    "        print('Problem 5 check passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3xGXSt3TAos"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Your solution should be like:\n",
    "```\n",
    "++++++++++ Test case [10] ++++++++++\n",
    "...\n",
    "Numpy overflow warning\n",
    "...\n",
    "Does not converge within epoch 10000\n",
    "\n",
    "++++++++++ Test case [0.1] ++++++++++\n",
    "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
    "Problem 5 check passed\n",
    "\n",
    "++++++++++ Test case [0.01] ++++++++++\n",
    "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
    "Problem 5 check passed\n",
    "\n",
    "++++++++++ Test case [0.001] ++++++++++\n",
    "Solution [ 99.78040508 699.88532482] found at epoch 5349\n",
    "Problem 5 check passed\n",
    "\n",
    "++++++++++ Test case [0.0001] ++++++++++\n",
    "Does not converge within epoch 10000\n",
    "\n",
    "++++++++++ Test case [1.e-05] ++++++++++\n",
    "Does not converge within epoch 10000\n",
    "\n",
    "++++++++++ Test case [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03] ++++++++++\n",
    "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
    "Problem 5 check passed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WPV-lMjTAos"
   },
   "source": [
    "### Double click this cell to edit:\n",
    "\n",
    "What is your conclusion from experiments with the above several test cases?\n",
    "```\n",
    "\n",
    "여러가지 방법으로(순수 파이썬 혹은 numpy를 이용하여) 두 점 사이의 거리와 그 함수의 기울기를 계산해보고,\n",
    "각 방법들의 연산 방식과 속도를 알 수 있었던 과제였습니다.\n",
    "\n",
    "확실히 순수 파이썬으로 연산을 진행하니 numpy대비 계산 속도가 느리고,\n",
    "벡터화된 연산을 사용할 수 없는 점이 단점으로 느껴졌습니다.\n",
    "특히나 대용량의 데이터를 처리할때는 그 단점이 더욱 부각되었던것 같습니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm_8EJ4uTAos"
   },
   "source": [
    "## Ethics:\n",
    "If you cheat, you will get negatgive of the total points.\n",
    "If the homework total is 22 and you cheat, you get -22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkQM1p8dTAos"
   },
   "source": [
    "## What to submit\n",
    "\n",
    "- Run **all cells** after restarting the kernel\n",
    "- Goto \"File -> Print Preview\"\n",
    "- Print the page as pdf\n",
    "- Pdf file name must be in a form of: homework_3_홍길동_202300001.pdf\n",
    "- Submit the pdf file in google classroom\n",
    "- No late homeworks will be accepted\n",
    "- Your homework will be graded on the basis of correctness, performance, and programming skills"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
